

The exponentially increasing number of processors and machines
available in current hardware are a great
opportunity to speed-up programs.
This is desired in image processing
and is frequently expressed with Data Parallelism.

Data-parallel programs express parallelism
via bulk-primitives over parallel data structures - e.g. \c{map/reduce}.
They perform well on flat data and with regular
non-recursive program flow.
However, most applications in need of parallelism
have irregular behaviour. Their
algorithms work with nested
arrays (e.g. images or matrices),
graphs, trees or complex recursion (e.g. clustering or machine learning).
Direct parallel implementation of such algorithms
in flat data parallelism results in
a performance penalty.
Programming parallel algorithms then mostly
becomes manual work and utterly complex.

In contrast, Nested Data Parallelism \cite{Belloch1996} lifts these limits
and enables the concise expression of irregularly-parallel programs
- while still compiling to efficient machine code.
It uses a non-trivial program transformation called 'Vectorization'
(or 'Flattening') where the original program is transformed
into an equivalent flat data-parallel program.

Due to properties like Immutability and Referential Transparency,
functional programming languages like Haskell are fruitful grounds for
sophisticated program transformations
and high-level expressiveness. They are key building
blocks for effective Nested Data Parallelism.
Haskell are its guidelines of conciseness
and "let the compiler do the work for you".
Nested Data Parallelism in Haskell
is an excellent example thereof.

\paragraph{}
All in all, this thesis aims to give an evaluation on
NDP and manual parallelization in the functional
programming language Haskell for application
in image processing.


\section{Aim and Methodology}
  The question on how Nested Data Parallelism (NDP) compares to
  conventional parallelism is tackled by the following methodology:
  An image processing algorithm with irregular behaviour
  is implemented in four variations. These variations are
  then compared on performance, human workload and other aspects.
  Finally a conclusion is drawn.
  
  \paragraph{}
    \ac $:=$ \algo, a conceptual image processing algorithm
    
    \seq $:=$ A direct sequential implementation of \ac

    \man $:=$ A manually-parallelized implementation of \ac
    
    \ndpn $:=$ A nested data-parallel implementation of \ac

    \ndpv $:=$ The vectorized implementation of \ac from \ndpn
  
  The sequential implementation \seq serves as a control-implementation
  for the parallel programs. The manual implementation \man
  will be compared against the nested data parallel ones.
  It is also distinguished between the original program \ndpn and
  its vectorization \ndpv. This distinctions enables
  to pin-point the advantages created by Vectorization.
  
  Given the generalisations of NDP into Haskell \cite{Harness2008},
  Haskell is an optimal choice for the implementation.
  The results of this thesis however can be easily adopted
  to related functional programming languages.
  
  Contrary to any expectations,
  the thesis does not present directly executable
  programs. NDP is Haskell is still in development and
  the program transformation is not yet completely implemented.
  The vectorization - usually done by the compiler
  - is done manually here.
  This leads to a theoretical analysis of all programs
  instead of benchmarking and statistical analysis.
  
  \algo was chosen for \ac because of its
  simplicity and limited-irregularity. It suits
  for three implementations and manual vectorization.

\section{Structure}
  This thesis begins with the basics in chapter \ref{chapter:basics}. It
  presents Haskell and Nested Data Parallelism with Vectorization.
  Parallel complexity measures and \algo are introduced either.
  The subsequent four chapters
  present and analyse four implementations.
  First, the sequential \seq
  is presented (chapter \ref{chapter:seq}).
  Second, comes the manually parallelized \man
  (chapter \ref{chapter:man}).
  Third, the nested data parallel \ndpn
  is given (chapter \ref{chapter:ndpn}).
  Fourth, its vectorization \ndpn is examined
  (chapter \ref{chapter:ndpv}).
  The thesis then compares and evaluates the programs
  in chapter \ref{chapter:results}.
  Finally, chapter \ref{chapter:outlook}
  summarizes the thesis, references to related work and gives an outlook.
  

